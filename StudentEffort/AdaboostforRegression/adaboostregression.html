
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Adaboost for Regression &#8212; Dr.Hadi Sadoghi Yazdi</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'StudentEffort/AdaboostforRegression/adaboostregression';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Midterm Exam - PCA" href="../Finall_PCA/finallPCA.html" />
    <link rel="prev" title="Midterm Exam - Gaussian Processes" href="../GP_Midterm/gp_final.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../Introduction_StudentEffort.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/Hadi_Sadoghi_Yazdi.png" class="logo__image only-light" alt="Dr.Hadi Sadoghi Yazdi - Home"/>
    <img src="../../_static/Hadi_Sadoghi_Yazdi.png" class="logo__image only-dark pst-js-only" alt="Dr.Hadi Sadoghi Yazdi - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../Introduction_StudentEffort.html">
                    Enduring Efforts of Students
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Student Effort PR</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Whyprojection1.html">What is Projection?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Star%20Coordinates/Star_Coordinates.html">Star Coordinates</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Covariance_Fekri/Covariance_Poorya.html">Covariance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear-least-square-final/least-square.html">Linear Least Square Method</a></li>






<li class="toctree-l1"><a class="reference internal" href="../ECG/ecg.html">ECG: Measurement of heart rate and probability of heart attack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../correntropy/correntropy.html">Understanding Correntropy as a Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Normalization/Normalization_1.html">Data Normalization</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Chernoff/ChernoffEsri.html">Chernoff Faces in ESRI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GloVe/GloVe1.html">GloVe: Word Representation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LinkageClustering1/linkageclustering2.html">Linkage Clustering Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Word2Vec/Word2Vec.html">Word2Vec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SOFM/SOFM.html">SOFM - Clustering and dimensionality reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../KNN/KNN.html">K Nearest-Neighbors KNN</a></li>


<li class="toctree-l1"><a class="reference internal" href="../Bayes_Estimation_HW/Bayes_Estimation_HW.html">Posterior Distribution Derivation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lms/lms.html">Least Mean Squares (LMS) Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../NMF/NonnegativeMatrixFactorization_NMF_Clustering.html">Nonnegative Matrix Factorization (NMF) for Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../RAG_%20Retrieval_Augmented_Generation/RAG_%20RetrievalAugmentedGeneration.html">RAG : Retrieval-Augmented Generation</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Student Effort ML</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../homeworkLLE/Homework_LLE.html">Locally Linear Embedding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bias_variance_tradeoff/bias_variance_tardeoff.html">Explanation of Bias-Variance Trade-Off</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Conjugate_Prior/Conjugate_Prior.html">Cojugate Prior</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ManifoldLearning/manifoldLearning.html">Manifold Learning Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ridge/ridge.html">Ridge Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../GP_Midterm/gp_final.html">Midterm Exam - Gaussian Processes</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">Adaboost for Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Finall_PCA/finallPCA.html">Midterm Exam - PCA</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Contact</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Contact_Me.html">Contact Me</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../About_Me.html">About Me</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/h-sadoghi/dr-sadoghi.git" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/h-sadoghi/dr-sadoghi.git/issues/new?title=Issue%20on%20page%20%2FStudentEffort/AdaboostforRegression/adaboostregression.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/StudentEffort/AdaboostforRegression/adaboostregression.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Adaboost for Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">AdaBoost for Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#steps-for-adaboost-regression">Steps for AdaBoost Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adaboost-regression-algorithm">AdaBoost Regression Algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-adaboost-for-regression-works">How AdaBoost for Regression Works</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adaboost-regression-numeric-example">AdaBoost Regression: Numeric Example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-dataset">Example Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-by-step-solution">Step-by-Step Solution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-initialize-the-distribution"><strong>Step 1: Initialize the Distribution</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-train-weak-learner"><strong>Step 2: Train Weak Learner</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-calculate-the-error-of-the-weak-learner"><strong>Step 3: Calculate the Error of the Weak Learner</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-compute-the-weight-alpha-1"><strong>Step 4: Compute the Weight ( \alpha_1 )</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-update-the-distribution"><strong>Step 5: Update the Distribution</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-final-prediction"><strong>Step 6: Final Prediction</strong></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="adaboost-for-regression">
<h1>Adaboost for Regression<a class="headerlink" href="#adaboost-for-regression" title="Link to this heading">#</a></h1>
<ul class="simple">
<li><p>Author  : Payam Parvazmanesh</p></li>
<li><p>Contact : <a class="reference external" href="mailto:payam&#46;manesh&#37;&#52;&#48;gmail&#46;com">payam<span>&#46;</span>manesh<span>&#64;</span>gmail<span>&#46;</span>com</a></p></li>
<li><p>Machine Learning</p></li>
</ul>
<section id="id1">
<h2>AdaBoost for Regression<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>AdaBoost can also be applied to regression tasks, where the goal is to predict continuous values rather than categorical ones. The basic steps and methodology are similar to the classification case, but with some adaptations to handle continuous outputs.</p>
<p>The general boosting procedure for regression still involves two key operations: <code class="docutils literal notranslate"><span class="pre">Adjust_Distribution</span></code> and <code class="docutils literal notranslate"><span class="pre">Combine_Outputs</span></code>. However, for regression, the loss function and the output of each weak learner are adjusted accordingly.</p>
<p><img alt="How AdaBoost for Regression Works" src="../../_images/adareg.png" /></p>
<p><strong>Cost Function for AdaBoost Regression</strong></p>
<p>The cost function in AdaBoost regression is designed to minimize the residuals of the predictions of the weak learners. We aim to minimize the following function:</p>
<div class="math notranslate nohighlight">
\[
J(\theta, \alpha) = E[l(e)] + \lambda G(\theta, \alpha)
\]</div>
<p>where <span class="math notranslate nohighlight">\(( e )\)</span> is the error (residuals), <span class="math notranslate nohighlight">\(( l )\)</span> is the loss function, <span class="math notranslate nohighlight">\(( \theta )\)</span> represents the parameters of the weak learners, and <span class="math notranslate nohighlight">\(( \alpha )\)</span> denotes the weights of the weak learners.</p>
<p>For regression, the error for the <span class="math notranslate nohighlight">\(( i )-th\)</span> sample is given by:</p>
<div class="math notranslate nohighlight">
\[
e_i = y_i - f(x_i)
\]</div>
<p>where <span class="math notranslate nohighlight">\(( f(x_i) )\)</span> is the prediction of the combined model, and <span class="math notranslate nohighlight">\(( y_i )\)</span> is the true value.</p>
<p>The weak learner’s output for a given sample <span class="math notranslate nohighlight">\(( x_i )\)</span> is denoted by <span class="math notranslate nohighlight">\(( h_m(x_i) )\)</span>, and the combined model’s prediction is given by:</p>
<div class="math notranslate nohighlight">
\[
H(x) = \sum_{m=1}^{T} \alpha_m h_m(x)
\]</div>
<p>Thus, the goal of boosting is to minimize the residual error by adjusting the weights <span class="math notranslate nohighlight">\(( \alpha_m )\)</span> for each weak learner.</p>
</section>
<section id="steps-for-adaboost-regression">
<h2>Steps for AdaBoost Regression<a class="headerlink" href="#steps-for-adaboost-regression" title="Link to this heading">#</a></h2>
<p><strong>Step 1: Initialize the Distribution</strong></p>
<p>Initially, all data points have equal weight:</p>
<div class="math notranslate nohighlight">
\[
D_1(x) = \frac{1}{m}
\]</div>
<p>where <span class="math notranslate nohighlight">\(( m )\)</span> is the total number of samples in the dataset.</p>
<p><strong>Step 2: Train Weak Learners</strong></p>
<p>For each boosting iteration <span class="math notranslate nohighlight">\(( t )\)</span>:</p>
<ul class="simple">
<li><p>Train a weak learner <span class="math notranslate nohighlight">\(( h_t(x) )\)</span> on the dataset <span class="math notranslate nohighlight">\(( D_t )\)</span>.</p></li>
<li><p>Compute the prediction <span class="math notranslate nohighlight">\(( h_t(x) )\)</span> and the residuals for each sample <span class="math notranslate nohighlight">\(( i )\)</span>:
$<span class="math notranslate nohighlight">\( e_i = y_i - h_t(x_i) \)</span>$</p></li>
</ul>
<p><strong>Step 3: Calculate the Error</strong></p>
<p>Calculate the error <span class="math notranslate nohighlight">\(( \epsilon_t )\)</span> for the weak learner:</p>
<div class="math notranslate nohighlight">
\[
\epsilon_t = \frac{\sum_{i=1}^{m} D_t(x_i) \cdot (y_i - h_t(x_i))^2}{\sum_{i=1}^{m} D_t(x_i)}
\]</div>
<p>The error <span class="math notranslate nohighlight">\(( \epsilon_t )\)</span> is the weighted mean squared error between the predictions of the weak learner and the true values.</p>
<p><strong>Step 4: Compute the Weight <span class="math notranslate nohighlight">\(( \alpha_t )\)</span></strong></p>
<p>If <span class="math notranslate nohighlight">\(( \epsilon_t &gt; 0.5 )\)</span>, then we set <span class="math notranslate nohighlight">\(( \alpha_t = 0 )\)</span> and continue with the next iteration. Otherwise, the weight <span class="math notranslate nohighlight">\(( \alpha_t )\)</span> of the weak learner is calculated using:</p>
<div class="math notranslate nohighlight">
\[
\alpha_t = \frac{1}{2} \ln \left( \frac{1 - \epsilon_t}{\epsilon_t} \right)
\]</div>
<p>This weight reflects the importance of the weak learner in the final model.</p>
<p><strong>Step 5: Update the Distribution</strong></p>
<p>Update the weight distribution for the next iteration based on the residuals:</p>
<div class="math notranslate nohighlight">
\[
D_{t+1}(x_i) = D_t(x_i) \cdot \exp \left( - \alpha_t (y_i - h_t(x_i))^2 \right)
\]</div>
<p>The distribution is normalized so that the weights sum to 1, ensuring it remains a valid probability distribution.</p>
<p><strong>Step 6: Final Prediction</strong></p>
<p>The final prediction is a weighted sum of all weak learners:</p>
<div class="math notranslate nohighlight">
\[
H(x) = \sum_{t=1}^{T} \alpha_t h_t(x)
\]</div>
<p>The final model combines the weak learners based on their weighted contribution to reduce the residual error.</p>
</section>
<section id="adaboost-regression-algorithm">
<h2>AdaBoost Regression Algorithm<a class="headerlink" href="#adaboost-regression-algorithm" title="Link to this heading">#</a></h2>
<p><strong>Input:</strong></p>
<ul class="simple">
<li><p>Dataset <span class="math notranslate nohighlight">\(( D = \{(x_1, y_1), (x_2, y_2), \dots, (x_m, y_m)\} )\)</span></p></li>
<li><p>Base learning algorithm <span class="math notranslate nohighlight">\(( L )\)</span></p></li>
<li><p>Number of learning rounds <span class="math notranslate nohighlight">\(( T )\)</span></p></li>
</ul>
<p><strong>Process:</strong></p>
<ol class="arabic">
<li><p>Initialize the weight distribution <span class="math notranslate nohighlight">\(( D_1(x) = \frac{1}{m} )\)</span>.</p></li>
<li><p>For <span class="math notranslate nohighlight">\(( t = 1, \dots, T )\)</span>:</p>
<ul>
<li><p>Train a weak learner <span class="math notranslate nohighlight">\(( h_t )\)</span> on the dataset <span class="math notranslate nohighlight">\(( D_t )\)</span>.</p></li>
<li><p>Compute the error <span class="math notranslate nohighlight">\(( \epsilon_t )\)</span> of <span class="math notranslate nohighlight">\(( h_t )\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(( \epsilon_t &gt; 0.5 )\)</span>, set <span class="math notranslate nohighlight">\(( \alpha_t = 0 )\)</span> and continue.</p></li>
<li><p>Calculate <span class="math notranslate nohighlight">\(( \alpha_t = \frac{1}{2} \ln \left( \frac{1 - \epsilon_t}{\epsilon_t} \right) )\)</span>.</p></li>
<li><p>Update the distribution for the next round:</p>
<div class="math notranslate nohighlight">
\[
     D_{t+1}(x_i) = D_t(x_i) \cdot \exp \left( - \alpha_t (y_i - h_t(x_i))^2 \right)
     \]</div>
</li>
</ul>
</li>
<li><p>End the loop.</p></li>
</ol>
<p><strong>Output:</strong>
The final hypothesis is given by:</p>
<div class="math notranslate nohighlight">
\[
H(x) = \sum_{t=1}^{T} \alpha_t h_t(x)
\]</div>
</section>
<section id="how-adaboost-for-regression-works">
<h2>How AdaBoost for Regression Works<a class="headerlink" href="#how-adaboost-for-regression-works" title="Link to this heading">#</a></h2>
<p>In this method, each weak learner corrects the errors made by previous learners. Initially, the weak learners may perform poorly, but with each iteration, the model improves by focusing on the data points that were previously mispredicted. The weights <span class="math notranslate nohighlight">\(( \alpha_t )\)</span> of the weak learners adjust the impact of each learner on the final prediction, with better-performing learners receiving higher weights.</p>
</section>
<section id="adaboost-regression-numeric-example">
<h2>AdaBoost Regression: Numeric Example<a class="headerlink" href="#adaboost-regression-numeric-example" title="Link to this heading">#</a></h2>
<p>Let’s walk through a simple numeric example of AdaBoost for Regression using a small dataset.</p>
<section id="example-dataset">
<h3>Example Dataset<a class="headerlink" href="#example-dataset" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(( x_i )\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(( y_i )\)</span> (True Value)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>5</p></td>
</tr>
</tbody>
</table>
</div>
<p>The objective is to use AdaBoost to predict the value of <span class="math notranslate nohighlight">\(( y )\)</span> based on <span class="math notranslate nohighlight">\(( x )\)</span>.</p>
</section>
<section id="step-by-step-solution">
<h3>Step-by-Step Solution<a class="headerlink" href="#step-by-step-solution" title="Link to this heading">#</a></h3>
</section>
<section id="step-1-initialize-the-distribution">
<h3><strong>Step 1: Initialize the Distribution</strong><a class="headerlink" href="#step-1-initialize-the-distribution" title="Link to this heading">#</a></h3>
<p>Initially, all data points have equal weight:</p>
<div class="math notranslate nohighlight">
\[
D_1(x_i) = \frac{1}{m} = \frac{1}{4} = 0.25 \quad \text{for each sample}
\]</div>
</section>
<section id="step-2-train-weak-learner">
<h3><strong>Step 2: Train Weak Learner</strong><a class="headerlink" href="#step-2-train-weak-learner" title="Link to this heading">#</a></h3>
<p>We will use a simple weak learner, for example, a regression tree with a depth of 1 (stump) that fits a constant value. This weak learner will predict the average value of the training set for each <span class="math notranslate nohighlight">\(( x )\)</span>.</p>
<p><strong>For the first iteration:</strong></p>
<ul class="simple">
<li><p>Train the weak learner <span class="math notranslate nohighlight">\(( h_1 )\)</span> on the data.</p></li>
<li><p>A regression tree with a single split gives the average of all <span class="math notranslate nohighlight">\(( y_i )\)</span>, which is:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
h_1(x) = \frac{2 + 3 + 3 + 5}{4} = 3.25
\]</div>
<p>So, <span class="math notranslate nohighlight">\(( h_1(x) )\)</span> predicts 3.25 for every input.</p>
</section>
<section id="step-3-calculate-the-error-of-the-weak-learner">
<h3><strong>Step 3: Calculate the Error of the Weak Learner</strong><a class="headerlink" href="#step-3-calculate-the-error-of-the-weak-learner" title="Link to this heading">#</a></h3>
<p>The error <span class="math notranslate nohighlight">\(( \epsilon_1 )\)</span> for weak learner <span class="math notranslate nohighlight">\(( h_1 )\)</span> is calculated as the weighted sum of squared errors:</p>
<div class="math notranslate nohighlight">
\[
\epsilon_1 = \frac{1}{4} \sum_{i=1}^{4} D_1(x_i) \cdot (y_i - h_1(x_i))^2
\]</div>
<p>For each <span class="math notranslate nohighlight">\(( x_i )\)</span>, the error is:</p>
<ul class="simple">
<li><p>For <span class="math notranslate nohighlight">\(( x_1 = 1 )\)</span>, error = <span class="math notranslate nohighlight">\(( (2 - 3.25)^2 = 1.5625 )\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(( x_2 = 2 )\)</span>, error = <span class="math notranslate nohighlight">\(( (3 - 3.25)^2 = 0.0625 )\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(( x_3 = 3 )\)</span>, error = <span class="math notranslate nohighlight">\(( (3 - 3.25)^2 = 0.0625 )\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(( x_4 = 4 )\)</span>, error = <span class="math notranslate nohighlight">\(( (5 - 3.25)^2 = 3.0625 )\)</span></p></li>
</ul>
<p>Now calculate the weighted error:</p>
<div class="math notranslate nohighlight">
\[
\epsilon_1 = \frac{1}{4} \left( 0.25 \cdot 1.5625 + 0.25 \cdot 0.0625 + 0.25 \cdot 0.0625 + 0.25 \cdot 3.0625 \right)
\]</div>
<div class="math notranslate nohighlight">
\[
\epsilon_1 = \frac{1}{4} \left( 0.390625 + 0.015625 + 0.015625 + 0.765625 \right)
\]</div>
<div class="math notranslate nohighlight">
\[
\epsilon_1 = \frac{1.1875}{4} = 0.296875
\]</div>
</section>
<section id="step-4-compute-the-weight-alpha-1">
<h3><strong>Step 4: Compute the Weight ( \alpha_1 )</strong><a class="headerlink" href="#step-4-compute-the-weight-alpha-1" title="Link to this heading">#</a></h3>
<p>The weight <span class="math notranslate nohighlight">\(( \alpha_1 )\)</span> for weak learner <span class="math notranslate nohighlight">\(( h_1 )\)</span> is calculated using:</p>
<div class="math notranslate nohighlight">
\[
\alpha_1 = \frac{1}{2} \ln \left( \frac{1 - \epsilon_1}{\epsilon_1} \right)
\]</div>
<p>Substituting <span class="math notranslate nohighlight">\(( \epsilon_1 = 0.296875 )\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\alpha_1 = \frac{1}{2} \ln \left( \frac{1 - 0.296875}{0.296875} \right) = \frac{1}{2} \ln \left( \frac{0.703125}{0.296875} \right)
\]</div>
<div class="math notranslate nohighlight">
\[
\alpha_1 = \frac{1}{2} \ln(2.367) = 0.4325
\]</div>
</section>
<section id="step-5-update-the-distribution">
<h3><strong>Step 5: Update the Distribution</strong><a class="headerlink" href="#step-5-update-the-distribution" title="Link to this heading">#</a></h3>
<p>Next, we update the distribution <span class="math notranslate nohighlight">\(( D_2(x_i) )\)</span> for the next iteration. The new weight distribution is:</p>
<div class="math notranslate nohighlight">
\[
D_2(x_i) = D_1(x_i) \cdot \exp \left( - \alpha_1 (y_i - h_1(x_i))^2 \right)
\]</div>
<p>For each sample <span class="math notranslate nohighlight">\(( i )\)</span>:</p>
<ul class="simple">
<li><p>For <span class="math notranslate nohighlight">\(( x_1 = 1 )\)</span>, update: <span class="math notranslate nohighlight">\(( 0.25 \cdot \exp(-0.4325 \cdot 1.5625) = 0.25 \cdot \exp(-0.6755) = 0.25 \cdot 0.5096 = 0.1274 )\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(( x_2 = 2 )\)</span>, update: <span class="math notranslate nohighlight">\(( 0.25 \cdot \exp(-0.4325 \cdot 0.0625) = 0.25 \cdot \exp(-0.0270) = 0.25 \cdot 0.9730 = 0.2432 )\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(( x_3 = 3 )\)</span>, update: <span class="math notranslate nohighlight">\(( 0.25 \cdot \exp(-0.4325 \cdot 0.0625) = 0.2432 ) (same as ( x_2 ))\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(( x_4 = 4 )\)</span>, update: <span class="math notranslate nohighlight">\(( 0.25 \cdot \exp(-0.4325 \cdot 3.0625) = 0.25 \cdot \exp(-1.3255) = 0.25 \cdot 0.2643 = 0.0661 )\)</span></p></li>
</ul>
<p>Now normalize the updated weights so they sum to 1:</p>
<div class="math notranslate nohighlight">
\[
\text{Total weight} = 0.1274 + 0.2432 + 0.2432 + 0.0661 = 0.6799
\]</div>
<p>Normalize:</p>
<div class="math notranslate nohighlight">
\[
D_2(x_1) = \frac{0.1274}{0.6799} = 0.1875, \quad D_2(x_2) = \frac{0.2432}{0.6799} = 0.3588
\]</div>
<div class="math notranslate nohighlight">
\[
D_2(x_3) = \frac{0.2432}{0.6799} = 0.3588, \quad D_2(x_4) = \frac{0.0661}{0.6799} = 0.0973
\]</div>
</section>
<section id="step-6-final-prediction">
<h3><strong>Step 6: Final Prediction</strong><a class="headerlink" href="#step-6-final-prediction" title="Link to this heading">#</a></h3>
<p>After one iteration, the model is:</p>
<div class="math notranslate nohighlight">
\[
H(x) = \alpha_1 h_1(x) = 0.4325 \cdot 3.25 = 1.405625
\]</div>
<p>Thus, the prediction after the first iteration is 1.405625 for all inputs.</p>
<p>This is a simple demonstration of the first iteration. In subsequent iterations, the weak learner will focus more on the data points that were predicted poorly, and the overall model will improve.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="c1"># Generate some example regression data</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>  <span class="c1"># 100 samples, 1 feature</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Sine function with noise</span>

<span class="c1"># Split the data into training and test sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Define the base regressor (a DecisionTreeRegressor)</span>
<span class="n">base_regressor</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Initialize AdaBoost Regressor</span>
<span class="n">ada_regressor</span> <span class="o">=</span> <span class="n">AdaBoostRegressor</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">base_regressor</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Train the AdaBoost Regressor</span>
<span class="n">ada_regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict on test set</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">ada_regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate Mean Squared Error</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean Squared Error: </span><span class="si">{</span><span class="n">mse</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Plot results</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">ada_regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;AdaBoost Prediction&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;AdaBoost Regression&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">20</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="n">base_regressor</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="c1"># Initialize AdaBoost Regressor</span>
<span class="ne">---&gt; </span><span class="mi">20</span> <span class="n">ada_regressor</span> <span class="o">=</span> <span class="n">AdaBoostRegressor</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">base_regressor</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span> <span class="c1"># Train the AdaBoost Regressor</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span> <span class="n">ada_regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="ne">TypeError</span>: AdaBoostRegressor.__init__() got an unexpected keyword argument &#39;base_estimator&#39;
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./StudentEffort\AdaboostforRegression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../GP_Midterm/gp_final.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Midterm Exam - Gaussian Processes</p>
      </div>
    </a>
    <a class="right-next"
       href="../Finall_PCA/finallPCA.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Midterm Exam - PCA</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">AdaBoost for Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#steps-for-adaboost-regression">Steps for AdaBoost Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adaboost-regression-algorithm">AdaBoost Regression Algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-adaboost-for-regression-works">How AdaBoost for Regression Works</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adaboost-regression-numeric-example">AdaBoost Regression: Numeric Example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-dataset">Example Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-by-step-solution">Step-by-Step Solution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-initialize-the-distribution"><strong>Step 1: Initialize the Distribution</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-train-weak-learner"><strong>Step 2: Train Weak Learner</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-calculate-the-error-of-the-weak-learner"><strong>Step 3: Calculate the Error of the Weak Learner</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-compute-the-weight-alpha-1"><strong>Step 4: Compute the Weight ( \alpha_1 )</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-update-the-distribution"><strong>Step 5: Update the Distribution</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-final-prediction"><strong>Step 6: Final Prediction</strong></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr.Hadi Sadoghi Yazdi
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024 Pattern Recognition Lab.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>